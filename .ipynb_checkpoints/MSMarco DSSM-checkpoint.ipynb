{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matchzoo as mz\n",
    "import pickle\n",
    "import simplejson as json\n",
    "from time import time\n",
    "import collections\n",
    "import sys\n",
    "from matchzoo.preprocessors import DSSMPreprocessor\n",
    "from matchzoo.processor_units import WordHashingUnit\n",
    "from matchzoo.data_generator import DynamicDataGenerator\n",
    "from matchzoo import chain_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiskDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, path, term_index, no_of_batches, start=0):\n",
    "        self.path = path\n",
    "        self.term_index = term_index\n",
    "        self.hashing_unit = WordHashingUnit(term_index)\n",
    "        self.term_len = len(term_index)\n",
    "        self.batch_size = 100\n",
    "        self.no_of_batches = no_of_batches\n",
    "        self.start = start\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.no_of_batches)\n",
    "    \n",
    "    def __data_generation(self, filename):\n",
    "        with open(self.path+filename, 'r', encoding='utf-8') as json_file:\n",
    "            data_blob = json.load(json_file)\n",
    "        \n",
    "        id_left = np.array(data_blob['id_left'])\n",
    "        id_right = np.array(data_blob['id_right'])\n",
    "        labels = np.array(data_blob['labels'])\n",
    "        text_left = np.empty((len(id_left), self.term_len+1))\n",
    "        text_right = np.empty((len(id_right), self.term_len+1))\n",
    "        \n",
    "        for i in range(len(id_left)):\n",
    "            vec = np.empty(self.term_len+1)\n",
    "            counted_tri_letters = collections.Counter(data_blob['text_left'][i])\n",
    "            for k, v in counted_tri_letters.items():\n",
    "                pos = self.term_index.get(k, 0)\n",
    "                vec[pos] = v\n",
    "            self.test = counted_tri_letters.items()\n",
    "            text_left[i] = vec\n",
    "        \n",
    "        for i in range(len(id_right)):\n",
    "            vec = np.zeros(self.term_len+1)\n",
    "            counted_tri_letters = collections.Counter(data_blob['text_right'][i])\n",
    "            for k, v in counted_tri_letters.items():\n",
    "                pos = self.term_index.get(k, 0)\n",
    "                vec[pos] = v\n",
    "            text_right[i] = vec\n",
    "        \n",
    "        X = {\n",
    "            'id_left': id_left,\n",
    "            'id_right': id_right,\n",
    "            'text_left': text_left,\n",
    "            'text_right': text_right\n",
    "        }\n",
    "        return X, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if type(index) is slice:\n",
    "            X = list()\n",
    "            Y = list()\n",
    "            \n",
    "            start = index.start if index.start else 0\n",
    "            stop = index.stop if index.stop else self.__len__()\n",
    "            step = index.step if index.step else 1\n",
    "            \n",
    "            for i in range(start, stop, step):\n",
    "                x, y = self.__getitem__(i)\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            \n",
    "            return X, Y\n",
    "                \n",
    "        index += self.start\n",
    "        filename = 'batch'+str(index)+'.json'\n",
    "        return self.__data_generation(filename)\n",
    "    \n",
    "    def unpack(self, start=None, stop=None, step=None):\n",
    "        X, Y = self[start:stop:step]\n",
    "        \n",
    "        all_X = X[0]\n",
    "        all_y = Y[0]\n",
    "        i = 1\n",
    "        while i < len(X):\n",
    "            all_X['id_left'] = np.hstack((all_X['id_left'], X[i]['id_left']))\n",
    "            all_X['id_right'] = np.hstack((all_X['id_right'], X[i]['id_right']))\n",
    "            all_X['text_left'] = np.vstack((all_X['text_left'], X[i]['text_left']))\n",
    "            all_X['text_right'] = np.vstack((all_X['text_right'], X[i]['text_right']))\n",
    "            \n",
    "            all_y = np.hstack((all_y, Y[i]))\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        return all_X, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_index = pickle.load(open('data/term_index_99.pkl', 'rb'))\n",
    "no_of_batches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DiskDataGenerator('data/', term_index, no_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_task = mz.tasks.Ranking()\n",
    "ranking_task.metrics = [\n",
    "    'mae', 'map', 'precision',\n",
    "    mz.metrics.Precision(k=3),\n",
    "    mz.metrics.DiscountedCumulativeGain(k=1),\n",
    "    mz.metrics.DiscountedCumulativeGain(k=3),\n",
    "    mz.metrics.DiscountedCumulativeGain(k=5),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=1),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=3),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=5)\n",
    "]\n",
    "model = mz.models.DSSMModel()\n",
    "input_shapes = [(len(term_index)+1,),(len(term_index)+1,)]\n",
    "model.params['input_shapes'] = input_shapes\n",
    "model.params['task'] = ranking_task\n",
    "model.guess_and_fill_missing_params()\n",
    "model.build()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example when used with tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 2s 216ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 1s 60ms/step - loss: nan - mean_absolute_error: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe27b4413c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran below code in virtualenv with normal tensorflow installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.7243 - mean_absolute_error: 0.8331\n",
      "Epoch 2/4\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.6920 - mean_absolute_error: 0.8153\n",
      "Epoch 3/4\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.6609 - mean_absolute_error: 0.7979\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.6310 - mean_absolute_error: 0.7807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f488e4146a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, epochs=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
